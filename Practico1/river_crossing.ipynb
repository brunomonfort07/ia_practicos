{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Letra práctico 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Práctico 1 - River Crossing\n",
    "Cuatro amigos llegan a un río a la noche. Allí se encuentran un puente estrecho y en\n",
    "mal estado, pero capaz de soportar el peso de dos personas a la vez. No contaban\n",
    "con este imprevisto y en su excursión nocturna sólo llevaban una antorcha. Ésta es\n",
    "imprescindible para cruzar el puente cada vez para que puedan ver dónde hay que\n",
    "pisar. Esto implica que cuando un par pasen de un lado al otro después uno debe\n",
    "volver a atrás para que puedan cruzar los demás. Alberta puede ir de un extremo al\n",
    "otro en un minuto, Bernardo tarda dos minutos en hacer el mismo recorrido. Carlos,\n",
    "con miedo al río, necesita cinco minutos para cruzar el puente, mientras que Diana\n",
    "requiere ocho minutos por un esguince en el pie que le hace ser la más lenta.\n",
    "Los cuatro amigos deben ser capaces de cruzar el río en exactamente 15 minutos.\n",
    "Cuando dos amigos cruzan el tiempo acumulado corresponde al amigo que demora\n",
    "más tiempo en cruzar.\n",
    "Se pide:\n",
    "1) Codificar un agente que ejecute acciones aleatorias sobre el ambiente\n",
    "(Random Agent).\n",
    "2) Codificar un agente que ejecute acciones que provienen de una lista de\n",
    "acciones predefinidas. El agente debe ejecutar las acciones en orden (Action\n",
    "List Agent).\n",
    "3) Codificar un agente que ejecute acciones basadas en una estrategia (Simple\n",
    "Reflex Agent).\n",
    "Lectura Recomendada\n",
    "Se recomienda repasar el uso básico de un ambiente de Gym/Gymnasium:\n",
    "https://www.gymlibrary.dev/content/basic_usage/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bruno apuntes práctico 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Antes de comenzar, ejecutar \n",
    "    *poetry install*\n",
    "    *pip install gymnasium*\n",
    "    )\n",
    "(Para ejecutar un archivo python --> *poetry run .\\random_agent.py*)\n",
    "\n",
    "Agente es director, personas seran parte del ambiente. La decisión la tomaremos nosotros como director.\n",
    "A principio tenemos las 4 personas del lado izqueirdo.\n",
    "Cruzan el puente, y luego elegimos las 2 personas que pasan, y uno tiene que volver porque tienen 1 antorcha.\n",
    "Así puedo seguir jugando.\n",
    "Objetivo: QUe pasen todos a la derecha, en 15 mins.\n",
    "\n",
    "Definir como es el ambiente:\n",
    "- PEAS\n",
    "    - Performance: Tiempo y cuantos de cada lado/haber llegado\n",
    "    - Desc. Ambiente: Descripción PDF\n",
    "    - Actuadores: Acciones. Mover hasta 2 personas para un lado y para el otro\n",
    "    - Sensores: Quienes estan \n",
    "- Observabilidad: Total, completa. La info es quien esta de cada lado y de que lado esta la antorcha.\n",
    "- Tomaremos personas como parte del ambiente.\n",
    "- Agente: Director que dirá quien se mueve para un lado y quien para el otro.\n",
    "- Deterministico. Cuadno hacemos un movimiento pasa algo.\n",
    "- Secuencial. Tenemos una secuencia de pasos que modifica el estado e impacta en el futuro\n",
    "- Táctico: Podemos tomarnos todo el tiempo del mundo para elegir que hacer. Agente trancado hasta que tomemos una decisión.\n",
    "- Discreto: Estados: Izq derecha.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctico 1: River Crossing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este práctico es comenzar a familiarizarse con el funcionamiento de los ambientes de gym/gymnasium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river_crossing_env import RiverCrossingEnv\n",
    "from input_agent import InputAgent\n",
    "from river_crossing_utils import finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Virtualenv\n",
      "Python:         3.13.3\n",
      "Implementation: CPython\n",
      "Path:           c:\\Users\\Bruno\\Desktop\\ia_practicos\\Practico1\\.venv\n",
      "Executable:     c:\\Users\\Bruno\\Desktop\\ia_practicos\\Practico1\\.venv\\Scripts\\python.exe\n",
      "Valid:          True\n",
      "\n",
      "Base\n",
      "Platform:   win32\n",
      "OS:         nt\n",
      "Python:     3.13.3\n",
      "Path:       C:\\Users\\Bruno\\AppData\\Local\\Programs\\Python\\Python313\n",
      "Executable: C:\\Users\\Bruno\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\n"
     ]
    }
   ],
   "source": [
    "!poetry env info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Espacio de acciones y observaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = RiverCrossingEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict('Aside': Discrete(2), 'Bside': Discrete(2), 'Cside': Discrete(2), 'Dside': Discrete(2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Aside': np.int64(1),\n",
       " 'Bside': np.int64(1),\n",
       " 'Cside': np.int64(1),\n",
       " 'Dside': np.int64(1)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict('direction': Discrete(2), 'person1': Discrete(4), 'person2': Discrete(4))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'direction': np.int64(1), 'person1': np.int64(2), 'person2': np.int64(1)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Me dará una accion aleatoria válida, solo a nivel de sintaxis.\n",
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comencemos realizando un agente input, en el cual proporcionaremos la acción para ser ejecutada sobre el ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInput: Right AB\\nInput: Left A\\nInput: Right CD\\nInput: Left B\\nInput: Right AB\\n\\nABCD //// Empty\\nCD //// AB\\nACD //// B\\nA //// BCD\\nAB //// CD\\nEmpty //// ABCD\\nCongratulations! You have solved the problem\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instanciar el entorno\n",
    "\n",
    "# Uno mismo toma las decisiones para ganar\n",
    "# \n",
    "\n",
    "# env = RiverCrossingEnv()\n",
    "# obs = env.reset()\n",
    "# done = False\n",
    "\n",
    "# # Instanciar el agente\n",
    "# rdm_agent = InputAgent()\n",
    "\n",
    "# # Esqueleto\n",
    "# while not done:\n",
    "#     # Renderizar el entorno (opcional)\n",
    "#     # Se puede renderizar con una UI, pero es costoso a nivel de cómputo.\n",
    "#     env.render()\n",
    "    \n",
    "#     # Obtener la acción del agente\n",
    "#     action = rdm_agent.next_action(obs)\n",
    "        \n",
    "#     # Ejecutar la acción en el entorno\n",
    "#     obs, reward, done, info = env.step(action)\n",
    "    \n",
    "# env.render()\n",
    "# finish(reward)\n",
    "\n",
    "'''\n",
    "Input: Right AB\n",
    "Input: Left A\n",
    "Input: Right CD\n",
    "Input: Left B\n",
    "Input: Right AB\n",
    "\n",
    "ABCD //// Empty\n",
    "CD //// AB\n",
    "ACD //// B\n",
    "A //// BCD\n",
    "AB //// CD\n",
    "Empty //// ABCD\n",
    "Congratulations! You have solved the problem\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codifique un agente que ejecute acciones aleatorias sobre el ambiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ver: random_agent.py__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random_agent import RandomAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABCD //// Empty\n",
      "ABCD //// Empty\n",
      "AD //// BC\n",
      "AD //// BC\n",
      "AD //// BC\n",
      "ABCD //// Empty\n",
      "CD //// AB\n",
      "CD //// AB\n",
      "CD //// AB\n",
      "CD //// AB\n",
      "CD //// AB\n",
      "CD //// AB\n",
      "CD //// AB\n",
      "CD //// AB\n",
      "CD //// AB\n",
      "CD //// AB\n",
      "CD //// AB\n",
      "CD //// AB\n",
      "CD //// AB\n",
      "CD //// AB\n",
      "CD //// AB\n",
      "CD //// AB\n",
      "CD //// AB\n",
      "CD //// AB\n",
      "CD //// AB\n",
      "CD //// AB\n",
      "CD //// AB\n",
      "CD //// AB\n",
      "ABCD //// Empty\n",
      "ABCD //// Empty\n",
      "ABCD //// Empty\n",
      "AB //// CD\n",
      "Try again!\n"
     ]
    }
   ],
   "source": [
    "# Instanciar el entorno\n",
    "env = RiverCrossingEnv()\n",
    "obs = env.reset()\n",
    "done = False\n",
    "\n",
    "# Instanciar el agente\n",
    "rdm_agent = RandomAgent()\n",
    "\n",
    "# Esqueleto\n",
    "while not done:\n",
    "    # Renderizar el entorno (opcional)\n",
    "    # Se puede renderizar con una UI, pero es costoso a nivel de cómputo.\n",
    "    env.render()\n",
    "    \n",
    "    # Obtener la acción del agente\n",
    "    action = rdm_agent.next_action(obs)\n",
    "        \n",
    "    # Ejecutar la acción en el entorno\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    \n",
    "env.render()\n",
    "finish(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action List Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codifique un agente que ejecute acciones que provienen de una lista de acciones predefinidas. El agente debe ejecutar las acciones en orden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ver: action_list_agent.py__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from action_list_agent import ActionListAgent\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABCD //// Empty\n",
      "CD //// AB\n",
      "ACD //// B\n",
      "A //// BCD\n",
      "AB //// CD\n",
      "Empty //// ABCD\n",
      "Congratulations! You have solved the problem\n"
     ]
    }
   ],
   "source": [
    "# Instanciar el entorno\n",
    "env = RiverCrossingEnv()\n",
    "obs = env.reset()\n",
    "done = False\n",
    "\n",
    "# Instanciar el agente\n",
    "lista_acciones: List[Dict[str, int]] = [\n",
    "    {\"direction\": 1, \"person1\": 0, \"person2\": 1},\n",
    "    {\"direction\": 0, \"person1\": 0, \"person2\": 0},\n",
    "    {\"direction\": 1, \"person1\": 2, \"person2\": 3},\n",
    "    {\"direction\": 0, \"person1\": 1, \"person2\": 1},\n",
    "    {\"direction\": 1, \"person1\": 0, \"person2\": 1}\n",
    "]\n",
    "\n",
    "alist_agent = ActionListAgent(lista_acciones)\n",
    "\n",
    "# Esqueleto\n",
    "while not done:\n",
    "    # Renderizar el entorno (opcional)\n",
    "    # Se puede renderizar con una UI, pero es costoso a nivel de cómputo.\n",
    "    env.render()\n",
    "    \n",
    "    # Obtener la acción del agente\n",
    "    action = alist_agent.next_action(obs)\n",
    "        \n",
    "    # Ejecutar la acción en el entorno\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    \n",
    "env.render()\n",
    "finish(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Reflex Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codifique un agente que ejecute acciones basadas en una estrategia.\n",
    "\n",
    "__Ver simple_reflex_agent.py__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
