{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tic_tac_toe import TicTacToe\n",
    "from agent import Agent\n",
    "from random_agent import RandomAgent\n",
    "from minimax_agent import AgentMinimax\n",
    "from expectimax_agent import AgentExpectimax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_winner(winner: int):\n",
    "    if winner == 0:\n",
    "        print(\"Empate\")\n",
    "    elif winner == 1:\n",
    "        print(\"Gano jugador 1\")\n",
    "    elif winner == 2:\n",
    "        print(\"Gano jugador 2\")\n",
    "    else:\n",
    "        print(\"Paso algo raro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# agent1 = RandomAgent(1) #0\n",
    "# agent2 = RandomAgent(2) #X\n",
    "# agents = [agent1, agent2]\n",
    "\n",
    "# tic_tac_toe = TicTacToe()\n",
    "# done = False\n",
    "# winner = -1\n",
    "# i = 0\n",
    "# while not done:\n",
    "#     i = (i+1) % 2\n",
    "#     pos = agents[i].next_action(tic_tac_toe)\n",
    "#     done, winner = tic_tac_toe.play(pos, agents[i].player)\n",
    "#     tic_tac_toe.render()\n",
    "# print_winner(winner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)  Implementar el agente Minimax y probarlo contra el agente aleatorio “RandomAgent”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lo hago aca porque me da pachorra la clase. Tiene problemas para ejecutar lo ultimo\n",
    "\n",
    "# from tic_tac_toe import TicTacToe\n",
    "# from agent import Agent\n",
    "# import random\n",
    "\n",
    "# class AgentMinimaxLocal(Agent):\n",
    "#     def __init__(self, player=1):\n",
    "#         super().__init__(player)\n",
    "\n",
    "#     def next_action(self, board: TicTacToe) -> tuple[int, int]:\n",
    "#         self.idx = 0\n",
    "#         pos, _ = self.minimax(board, self.player)\n",
    "#         return pos\n",
    "\n",
    "#     def heuristic_utility(self, board: TicTacToe) -> int:\n",
    "#         # Completar con función de evaluación\n",
    "#         # La función de evaluación estima el valor de un estado del juego que no es terminal (es decir, cuando no se ha llegado aún al final de \n",
    "#         # la partida) y sirve para decidir cuál movimiento es mejor cuando el árbol no puede explorarse completamente.\n",
    "#         # Sirve para limitar la altura a evaluar del arbol, cuando la busqueda crece de forma exponencial.\n",
    "#         return 0\n",
    "\n",
    "#     def minimax(self, board: TicTacToe, player: int) -> tuple[tuple[int, int], int]:\n",
    "\n",
    "#         # Caso base\n",
    "#         gameEnded, finalValue = board.is_end() # finalValue = U(s)\n",
    "#         if (gameEnded):\n",
    "#             return None, finalValue\n",
    "\n",
    "#         # Casos no base\n",
    "#         actions = board.get_available_cells()\n",
    "#         random.shuffle(actions)\n",
    "#         action_nodes = []\n",
    "#         for action in actions:\n",
    "#             child_node = board.clone()\n",
    "#             child_node.play(action, player)\n",
    "#             action_nodes.append((action, child_node))\n",
    "\n",
    "#         value = 0\n",
    "#         chosen_action = None\n",
    "\n",
    "#         if player != self.player:  # mini\n",
    "#             # Buscar acción que minimiza el valor\n",
    "#             value = float('inf')\n",
    "#             for child_node in action_nodes:\n",
    "#                 node_action = child_node[0]\n",
    "#                 node_board = child_node[1]\n",
    "#                 _, uAux = self.minimax(node_board, self.next_player(player))\n",
    "#                 if uAux < value:\n",
    "#                     chosen_action, value = node_action, uAux\n",
    "\n",
    "#         else:  # max (player == self.player)\n",
    "#             # Buscar acción que maximiza el valor\n",
    "#             value = float('-inf')\n",
    "#             for child_node in action_nodes:\n",
    "#                 node_action = child_node[0]\n",
    "#                 node_board = child_node[1]\n",
    "#                 _, uAux = self.minimax(node_board, self.next_player(player))\n",
    "#                 if uAux > value:\n",
    "#                     chosen_action, value = node_action, uAux\n",
    "\n",
    "#         return chosen_action, value\n",
    "    \n",
    "#     def next_player(self, player: int):\n",
    "#         return (player % 2) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "---------------------------\n",
      "|   -   ||   -   ||   -   |\n",
      "---------------------------\n",
      "|   -   ||   -   ||   -   |\n",
      "---------------------------\n",
      "|   -   ||   -   ||   O   |\n",
      "---------------------------\n",
      "===========================\n",
      "---------------------------\n",
      "|   -   ||   X   ||   -   |\n",
      "---------------------------\n",
      "|   -   ||   -   ||   -   |\n",
      "---------------------------\n",
      "|   -   ||   -   ||   O   |\n",
      "---------------------------\n",
      "===========================\n",
      "---------------------------\n",
      "|   -   ||   X   ||   -   |\n",
      "---------------------------\n",
      "|   -   ||   O   ||   -   |\n",
      "---------------------------\n",
      "|   -   ||   -   ||   O   |\n",
      "---------------------------\n",
      "===========================\n",
      "---------------------------\n",
      "|   -   ||   X   ||   -   |\n",
      "---------------------------\n",
      "|   -   ||   O   ||   -   |\n",
      "---------------------------\n",
      "|   X   ||   -   ||   O   |\n",
      "---------------------------\n",
      "===========================\n",
      "---------------------------\n",
      "|   O   ||   X   ||   -   |\n",
      "---------------------------\n",
      "|   -   ||   O   ||   -   |\n",
      "---------------------------\n",
      "|   X   ||   -   ||   O   |\n",
      "---------------------------\n",
      "Gano jugador 2\n"
     ]
    }
   ],
   "source": [
    "agent1 = RandomAgent(1) #X\n",
    "agent2 = AgentMinimax(2) #O\n",
    "agents = [agent1, agent2]\n",
    "\n",
    "tic_tac_toe = TicTacToe()\n",
    "done = False\n",
    "winner = -1\n",
    "i = 0\n",
    "while not done:\n",
    "    i = (i+1) % 2\n",
    "    pos = agents[i].next_action(tic_tac_toe)\n",
    "    done, winner = tic_tac_toe.play(pos, agents[i].player)\n",
    "    tic_tac_toe.render()\n",
    "print_winner(winner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2)  Implementar Expectimax y probarlo contra “RandomAgent”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tic_tac_toe import TicTacToe\n",
    "# from agent import Agent\n",
    "\n",
    "\n",
    "# class AgentExpectimax(Agent):\n",
    "#     def __init__(self, player=1, max_depth: int = 10):\n",
    "#         super().__init__(player)\n",
    "#         self.max_depth = max_depth\n",
    "\n",
    "#     def next_action(self, board: TicTacToe) -> tuple[int, int]:\n",
    "#         self.idx = 0\n",
    "#         pos, _ = self.expectimax(board, self.player, self.max_depth)\n",
    "#         return pos\n",
    "\n",
    "#     def heuristic_utility(self, board: TicTacToe) -> int:\n",
    "#         # Completar con función de evaluación\n",
    "#         return 0\n",
    "\n",
    "#     def expectimax(\n",
    "#         self, board: TicTacToe, player: int, depth: int\n",
    "#     ) -> tuple[tuple[int, int], int]:\n",
    "\n",
    "\n",
    "#         # TODO: Completar\n",
    "#         # Caso base\n",
    "#         gameEnded, finalValue = board.is_end() # finalValue = U(s)\n",
    "#         if (gameEnded):\n",
    "#             return None, finalValue\n",
    "        \n",
    "#         # Casos no base\n",
    "#         actions = board.get_available_cells()\n",
    "#         action_nodes = []\n",
    "#         for action in actions:\n",
    "#             child_node = board.clone()\n",
    "#             child_node.play(action, player)\n",
    "#             action_nodes.append((action, child_node))\n",
    "\n",
    "#         value = 0\n",
    "#         chosen_action = None\n",
    "#         if player != self.player:  # Expecti\n",
    "#             # Calcular valor promedio de las acciones del oponente\n",
    "#             total_value = 0\n",
    "#             for child_node in action_nodes:\n",
    "#                 node_action = child_node[0]\n",
    "#                 node_board = child_node[1]\n",
    "#                 _, uAux = self.expectimax(node_board, self.next_player(player), depth - 1)\n",
    "#                 total_value += uAux\n",
    "#             #  la función pol_prob(s, a) representa la probabilidad de que en el estado s se elija la acción a\n",
    "\n",
    "#             value = total_value / len(action_nodes)\n",
    "#             # print(\"Current Value\", value)\n",
    "#         else:  # max\n",
    "#             # Buscar acción que maximiza el valor\n",
    "#             value = float('-inf')\n",
    "#             for child_node in action_nodes:\n",
    "#                 node_action = child_node[0]\n",
    "#                 node_board = child_node[1]\n",
    "#                 _, uAux = self.expectimax(node_board, self.next_player(player), depth - 1)\n",
    "#                 if uAux > value:\n",
    "#                     chosen_action, value = node_action, uAux\n",
    "\n",
    "#         # pol_prob(s, a) representa la probabilidad de que en el estado s se elija la acción a\n",
    "#         # juego.suc(s, a) devuelve el nuevo estado que resulta de aplicar la acción a sobre el estado s.\n",
    "\n",
    "#         return chosen_action, value\n",
    "\n",
    "#     def next_player(self, player: int):\n",
    "#         return (player % 2) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "---------------------------\n",
      "|   -   ||   -   ||   -   |\n",
      "---------------------------\n",
      "|   -   ||   -   ||   -   |\n",
      "---------------------------\n",
      "|   O   ||   -   ||   -   |\n",
      "---------------------------\n",
      "===========================\n",
      "---------------------------\n",
      "|   X   ||   -   ||   -   |\n",
      "---------------------------\n",
      "|   -   ||   -   ||   -   |\n",
      "---------------------------\n",
      "|   O   ||   -   ||   -   |\n",
      "---------------------------\n",
      "===========================\n",
      "---------------------------\n",
      "|   X   ||   -   ||   O   |\n",
      "---------------------------\n",
      "|   -   ||   -   ||   -   |\n",
      "---------------------------\n",
      "|   O   ||   -   ||   -   |\n",
      "---------------------------\n",
      "===========================\n",
      "---------------------------\n",
      "|   X   ||   X   ||   O   |\n",
      "---------------------------\n",
      "|   -   ||   -   ||   -   |\n",
      "---------------------------\n",
      "|   O   ||   -   ||   -   |\n",
      "---------------------------\n",
      "===========================\n",
      "---------------------------\n",
      "|   X   ||   X   ||   O   |\n",
      "---------------------------\n",
      "|   -   ||   O   ||   -   |\n",
      "---------------------------\n",
      "|   O   ||   -   ||   -   |\n",
      "---------------------------\n",
      "Gano jugador 2\n"
     ]
    }
   ],
   "source": [
    "agent1 = RandomAgent(1) #X\n",
    "agent2 = AgentExpectimax(2) #O\n",
    "agents = [agent1, agent2]\n",
    "\n",
    "tic_tac_toe = TicTacToe()\n",
    "done = False\n",
    "winner = -1\n",
    "i = 0\n",
    "while not done:\n",
    "    i = (i+1) % 2\n",
    "    pos = agents[i].next_action(tic_tac_toe)\n",
    "    done, winner = tic_tac_toe.play(pos, agents[i].player)\n",
    "    tic_tac_toe.render()\n",
    "print_winner(winner)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
